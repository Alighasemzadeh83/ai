{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.row_count = 3\n",
    "        self.col_count = 3\n",
    "        self.action_size = self.row_count * self.col_count\n",
    "    \n",
    "    def get_initial_state(self):\n",
    "        return np.zeros((self.row_count, self.col_count), dtype=int)\n",
    "    \n",
    "    def get_next_state(self, state, action, player):\n",
    "        row = action // self.row_count\n",
    "        col = action % self.col_count\n",
    "        new_state = state.copy()\n",
    "        new_state[row, col] = player\n",
    "        return new_state\n",
    "    \n",
    "    def get_valid_actions(self, state):\n",
    "        return (state.flatten() == 0).astype(int)\n",
    "    \n",
    "    def check_win(self, state, action):\n",
    "        if action is None:\n",
    "            return False\n",
    "        row = action // self.row_count\n",
    "        col = action % self.col_count\n",
    "        player = state[row, col]\n",
    "\n",
    "        return (\n",
    "            np.sum(state[row, :]) == player * self.col_count\n",
    "            or np.sum(state[:, col]) == player * self.row_count\n",
    "            or np.sum(np.diag(state)) == player * self.row_count\n",
    "            or np.sum(np.diag(np.fliplr(state))) == player * self.row_count\n",
    "        )\n",
    "    \n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state, action):\n",
    "            return 1, True\n",
    "        if np.sum(self.get_valid_actions(state)) == 0:\n",
    "            return 0, True\n",
    "        return 0, False\n",
    "    \n",
    "    def get_opponent(self, player):\n",
    "        return -player\n",
    "    \n",
    "    def get_opponent_value(self, value):\n",
    "        return -value\n",
    "    \n",
    "    def change_perspective(self, state, player):\n",
    "        return state * player\n",
    "    \n",
    "    def get_encoded_state(self, state):\n",
    "        encoded_state = np.stack(\n",
    "            (state == -1, state == 0, state == 1)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        return encoded_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, game, num_resblocks=3, hidden_size=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.startBlock = nn.Sequential(\n",
    "            nn.Conv2d(3, hidden_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.backBone = nn.ModuleList(\n",
    "            [ResBlock(hidden_size) for i in range(num_resblocks)]\n",
    "        )\n",
    "\n",
    "        self.policyHead = nn.Sequential(\n",
    "            nn.Conv2d(hidden_size, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * game.row_count * game.col_count, game.action_size)\n",
    "        )\n",
    "\n",
    "        self.valueHead = nn.Sequential(\n",
    "            nn.Conv2d(hidden_size, 3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * game.row_count * game.col_count, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.startBlock(x)\n",
    "        for resBlock in self.backBone:\n",
    "            x = resBlock(x)\n",
    "        policy = self.policyHead(x)\n",
    "        value = self.valueHead(x)\n",
    "        return policy, value\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_size)\n",
    "        self.conv2 = nn.Conv2d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "\n",
    "        self.children = []\n",
    "\n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_ucb = ucb\n",
    "                best_child = child\n",
    "        \n",
    "        return best_child\n",
    "    \n",
    "    def get_ucb(self, child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
    "        return q_value + self.args['C'] * child.prior * np.sqrt(self.visit_count) / (1 + child.visit_count)\n",
    "    \n",
    "    def expand(self, policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state, action, 1)\n",
    "                child_state = self.game.change_perspective(child_state, player=-1)\n",
    "\n",
    "                child = Node(self.game, self.args, child_state, parent=self, action_taken=action, prior=prob)\n",
    "                self.children.append(child)\n",
    "        return child\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        self.visit_count += 1\n",
    "        self.value_sum += value\n",
    "\n",
    "        value = self.game.get_opponent_value(value)\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)\n",
    "        \n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, game, args, model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "        root = Node(self.game, self.args, state)\n",
    "\n",
    "        for search in range(self.args['num_searches']):\n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "            \n",
    "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "            value = self.game.get_opponent_value(value)\n",
    "\n",
    "            if not is_terminal:\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(self.game.get_encoded_state(node.state)).unsqueeze(0)\n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=-1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = self.game.get_valid_actions(node.state)\n",
    "                policy *= valid_moves\n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                value = value.item()\n",
    "\n",
    "                node = node.expand(policy)\n",
    "\n",
    "            node.backpropagate(value)\n",
    "\n",
    "        action_probs = np.zeros(self.game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self, model, optimizer, game, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game, args, model)\n",
    "\n",
    "    def self_play(self):\n",
    "        memory = []\n",
    "        player = 1\n",
    "        state = self.game.get_initial_state()\n",
    "\n",
    "        while True:\n",
    "            neutral_state = self.game.change_perspective(state, player)\n",
    "            action_probs = self.mcts.search(neutral_state)\n",
    "\n",
    "            memory.append((neutral_state, action_probs, player))\n",
    "\n",
    "            action = np.random.choice(self.game.action_size, p=action_probs)\n",
    "\n",
    "            state = self.game.get_next_state(state, action, player)\n",
    "\n",
    "            value, is_terminal = self.game.get_value_and_terminated(state, action)\n",
    "\n",
    "            if is_terminal:\n",
    "                returnMemory = []\n",
    "                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
    "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
    "                    returnMemory.append((\n",
    "                        self.game.get_encoded_state(hist_neutral_state),\n",
    "                        hist_action_probs,\n",
    "                        hist_outcome\n",
    "                    ))\n",
    "                return returnMemory\n",
    "\n",
    "            player = self.game.get_opponent(player)\n",
    "\n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "\n",
    "        for batch_idx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batch_idx:min(batch_idx + self.args['batch_size'], len(memory))]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "\n",
    "            state = torch.tensor(state, dtype=torch.float32)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32)\n",
    "\n",
    "            out_policy, out_value = self.model(state)\n",
    "\n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def learn(self):\n",
    "        for iteration in range(self.args['num_iterations']):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            for self_play_iteration in trange(self.args['num_self_play_iterations']):\n",
    "                memory += self.self_play()\n",
    "            \n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args['num_epochs']):\n",
    "                self.train(memory)\n",
    "            \n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649618b3aefe4f08a30555710a8eb2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4dd51276c04ffa90337faa481b000f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c122dcaa4b94ae4a7f92546a7fe8e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf51448259841c8ae913d100e82e2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366f558339894977b370628d64442c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c253957574c719a841f11fe8eb524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tictactoe = TicTacToe()\n",
    "\n",
    "model = ResNet(tictactoe, 4, 64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 60,\n",
    "    'num_iterations': 3,\n",
    "    'num_self_play_iterations': 10,\n",
    "    'num_epochs': 4,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "alphazero = AlphaZero(model, optimizer, tictactoe, args)\n",
    "alphazero.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22471562027931213 [0.22360985 0.12611541 0.05029601 0.07053461 0.02027852 0.10792029\n",
      " 0.13038322 0.18369399 0.08716807]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tictactoe = TicTacToe()\n",
    "\n",
    "state = tictactoe.get_initial_state()\n",
    "state = tictactoe.get_next_state(state, 2, 1)\n",
    "state = tictactoe.get_next_state(state, 4, -1)\n",
    "state = tictactoe.get_next_state(state, 6, 1)\n",
    "state = tictactoe.get_next_state(state, 8, -1)\n",
    "\n",
    "\n",
    "encoded_state = tictactoe.get_encoded_state(state)\n",
    "\n",
    "\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "\n",
    "model = ResNet(tictactoe, 4, 64)\n",
    "model.load_state_dict(torch.load('model_2.pt'))\n",
    "\n",
    "policy, value = model(tensor_state)\n",
    "value = value.item()\n",
    "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "print(value, policy)\n",
    "\n",
    "plt.bar(range(tictactoe.action_size), policy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
